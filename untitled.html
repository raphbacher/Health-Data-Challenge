<h2 data-label="142644" class="ltx_title_subsection">cent coupantsContext</h2><div><b>Intro</b></div><div>State of the art for benchmarking</div><div><div>eg :</div><div>AN EXAMINATION OF PROCEDURES FOR DETERMINING THE NUMBER OF CLUSTERS IN A DATA SET (Milligan et al.)</div><div>Comprehensive benchmarking and ensemble approaches for metagenomic classifiers (McIntyre et al.)</div><div>A comprehensive database for benchmarking imaging systems (Panetta et al.)</div><div></div><div>State of the art for data challenge organization (DREAM challenge, MVA Master yearly challenge, AMPS Hackathon, Codalab platform&nbsp;eg)</div><div></div><div></div><div>State of the art for data challenge organization (DREAM challenge, MVA Master yearly challenge, AMPS Hackathon, Codalab platform&nbsp;eg)</div><div></div><div><b>Challenge general considerations</b></div><ul><li>Amount of participants: 34 from 5 different countries and from different backgrounds (bioinfo/applied maths/statisticians/computer science)</li><li>DNA methylation (amount of packages + simulated data)</li><li></li></ul><div></div><div></div><div></div><div></div><div></div></div><div><div></div><div></div></div><div></div><div></div><div>M&amp;M</div><h2 data-label="481204" class="ltx_title_subsection"></h2><h2 data-label="739227" class="ltx_title_subsection"><b>Results</b></h2><h3 data-label="222652" class="ltx_title_subsubsection">main table</h3><div>Framework displayed in the table</div><div># Accounting for confounders</div><div># Choosing K</div><div># Initial estimation of matrices</div><div># Matrix factorization techniques</div><div># MAE Score</div><div># DMSE Score</div><div># Did you try to avoid overfitting</div><div># Time at which the solution was submitted</div><div></div><h3 data-label="222652" class="ltx_title_subsubsection">meta-results</h3><div>Data Challenge provided an environment for :</div><div>&nbsp;&nbsp;&nbsp;&nbsp;constant feedback for users (from other team members as well as from the codalab scoring) </div><div>&nbsp;&nbsp;&nbsp;&nbsp;for developers of R packages -&gt; possible improvements of methods</div><div>&nbsp; &nbsp; feedback and discussion for participants -&gt; gain of knowledge (how to use packages the best way w/ the advices from experts) and improvement of working skills</div><div>&nbsp; &nbsp; discussion about the necessity of good state of the art, independent benchmark data for this research field</div><div></div><h2 data-label="448640" class="ltx_title_subsection">Discussion </h2><div></div><h3 data-label="952780" class="ltx_title_subsubsection">Benchmarking</h3><div></div><div>Pilot benchmarking in this data challenge workshop</div><div>Advantage:&nbsp; data simulated by individuals who were not competing / developing solutions, therefore solutions were independent of generating methodology</div><div>Will lead to more comprehensive benchmarking project that follows similar methodology but in a more structured format.</div><div>Other similar benchmarking efforts (literature review)</div><div>However, the extent, number of methods included, and the scope of scenarios those studies considered is not satisfactory (<b>Suppl.&nbsp;Table XX</b>) as well as the versioning.</div><div></div><div></div><div></div>