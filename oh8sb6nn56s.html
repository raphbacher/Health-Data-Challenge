<div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div></div><h2 data-label="481204" class="ltx_title_subsection"></h2><h2 data-label="739227" class="ltx_title_subsection"><b>Results</b></h2><h3 data-label="222652" class="ltx_title_subsubsection"></h3><h3 data-label="222652" class="ltx_title_subsubsection">main table = main result</h3><div>Framework displayed in the table</div><div><b><i>Result 1</i></b></div><div><b>1-3 lines by team asked after their presentation on Friday morning</b></div><div></div><div># Accounting for confounders</div><div># feature selection</div><div># Choosing K</div><div># Initial estimation of matrices</div><div># Matrix factorization techniques</div><div># MAE Score</div><div># DMSE Score</div><div># Did you try to avoid overfitting</div><div>Highlight the framework with the best scores</div><div></div><div><b><i>Result 2</i></b></div><h3 data-label="222652" class="ltx_title_subsubsection"><b><i>Evolution of scores (Raphael Bacher)</i></b></h3><h3 data-label="222652" class="ltx_title_subsubsection"></h3><div></div><h3 data-label="222652" class="ltx_title_subsubsection">meta-results</h3><div>Team organization and composition </div><div>Question : evaluate skills in biology and computing/stat</div><div><div>Question : influenced by other teams during the challenge (Y/N)</div><div><div>Question : did you implement the code provided after the first challenge for the second one ?</div><div>Question : how did you work in group ? Patterns : work division (parallel), separately then together (pyramidal), together working on the same problems (spaghetti -or parrot scale :)) ?</div><div>Question :&nbsp;&nbsp; </div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div></div><div></div><div>Data Challenge provided an environment for :</div><div>&nbsp;&nbsp;&nbsp;&nbsp;constant feedback for users (from other team members as well as from the codalab scoring) </div><div>&nbsp;&nbsp;&nbsp;&nbsp;for developers of R packages -&gt; possible improvements of methods</div><div>&nbsp; &nbsp; feedback and discussion for participants -&gt; gain of knowledge (how to use packages the best way w/ the advice from experts) and improvement of working skills</div><div>&nbsp; &nbsp; discussion about the necessity of a good state of the art, independent benchmark data for this research field</div><div></div><h2 data-label="448640" class="ltx_title_subsection">Discussion </h2><div></div><h3 data-label="952780" class="ltx_title_subsubsection">Benchmarking</h3><div></div><div>The number of computational methods for the cell type inference based on DNA methylation data is growing steadily (see&nbsp;<b>Suppl. Table XX</b>). This calls for a comprehensive, unbiased and &nbsp;exhaustive benchmarking study. In recent years several benchmarking studies were performed&nbsp;(<b>Suppl.&nbsp;Table XX</b>) .However, the extent and number of methods included, and the scope of scenarios those studies considered is not satisfactory as well as the versioning. In the present Data Challenge we performed a pilot benchmarking study.he main advantage of whichwas that&nbsp; data simulated by individuals who were not competing / developing solutions, therefore solutions were independent of generating methodology.&nbsp;</div><div>This work will lead to a more comprehensive benchmarking project that follows a similar methodology but in a more structured format.</div><div></div><div></div><div></div><div></div>