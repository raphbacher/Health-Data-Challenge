<h1 data-label="707101" class="ltx_title_section">Discussion</h1><div></div><div>The number of computational methods for the cell type inference based on DNA methylation data is growing steadily (see&nbsp;<b>Suppl. Table XX</b>).  This calls for a comprehensive, unbiased and &nbsp;exhaustive benchmarking  study. In recent years several benchmarking studies were performed&nbsp;(<b>Suppl.&nbsp;Table XX</b>).  However, these studies entailed unsatisfactory heterogeneity in the  extent and number of methods included, as well as the versioning of the  methods assessed. In the present Data Challenge we performed a pilot  benchmarking study, the main advantage of which was that&nbsp; data sets were  simulated by individuals who were not competing&nbsp; in the development of  solutions; therefore solutions were independent of generating  methodology.&nbsp;This work will lead to a more comprehensive benchmarking  project that follows a similar methodology but in a more structured  format.</div><div></div><h2 data-label="358253" class="ltx_title_subsection">Cancer heterogeneity deconvolution : general consideration</h2><div>+ in-depth discussion of the results</div><div>+ amelioration of methods (Andy?, Pavlo?, Eugene"?)</div><div>+ future directions for the methods</div><div></div><div></div><h2 data-label="787188" class="ltx_title_subsection">Cancer heterogeneity deconvolution : recommandations to take into account confounders effect</h2><div>+ R package</div><h2 data-label="756183" class="ltx_title_subsection"></h2><h2 data-label="441721" class="ltx_title_subsection">Interest of data challenges in benchmarking studies</h2><div>Highlights: Unbiased Blueprint for other fields </div><div>Thinking upfront about parameters,<b> </b> instead of choosing a code and play around with parameters </div><div> Methods are created, no real gold standard benchmarking in this  area. </div><div>Data Challenge provided an environment for :</div><div>+ constant feedback for users (from other team members as well as from the codalab scoring)&nbsp;</div><div>+ for developers of R packages -&gt; possible improvements of methods</div><div>+ feedback and discussion for participants -&gt; gain of knowledge (how to use packages the best way w/ the advice from experts) and improvement of working skills</div><div></div><h2 data-label="521719" class="ltx_title_subsection">Guidelines to organize data challenges to benchmark computational methods in biology</h2><div>+ discussion about the necessity of a good state of the art, independent benchmark data for this research field</div><div>+ impact of team organization and composition (evaluate skills in biology and computing/stat,  influenced by other teams during the challenge?, did you implement the code provided after the first challenge for the second one how did you work in group ? Patterns : work division (parallel), separately then together (pyramidal), together working on the same problems (spaghetti -or parrot scale :))&nbsp;</div><div></div><div></div><div></div><blockquote class="au-no-left-border"><div> </div><div></div></blockquote><div>&nbsp;</div><div>&nbsp;</div><h2 data-label="481204" class="ltx_title_subsection"></h2><h2 data-label="739227" class="ltx_title_subsection"></h2><div></div><div></div><div></div><div></div><div></div><h3 data-label="222652" class="ltx_title_subsubsection"></h3><h3 data-label="222652" class="ltx_title_subsubsection"></h3><div></div><h3 data-label="222652" class="ltx_title_subsubsection"></h3><div></div><div> </div><div></div><div></div><div></div><div></div><h2 data-label="448640" class="ltx_title_subsection"> </h2><div></div><h3 data-label="952780" class="ltx_title_subsubsection"></h3><div></div><div></div><div></div><div></div><div></div><div></div>